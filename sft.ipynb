{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 7\"\n",
    "#import os\n",
    "#os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "#os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "#import sklearn\n",
    "import torch\n",
    "import re\n",
    "import wandb\n",
    "\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments,BitsAndBytesConfig\n",
    "from datasets import load_dataset\n",
    "# from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "# from peft import AutoPeftModelForCausalLM, LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType\n",
    "# from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "\n",
    "# from accelerate import Accelerator\n",
    "\n",
    "# from Prompt import Prompt\n",
    "\n",
    "# import torch\n",
    "# import bitsandbytes as bnb\n",
    "# import fire\n",
    "# import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "random.seed(1958)\n",
    "class Prompt:\n",
    "    def __init__(self, prompt_path) -> None:\n",
    "        assert os.path.isfile(prompt_path), \"Please specify a prompt template\"\n",
    "        with open(prompt_path, 'r') as f:\n",
    "            raw_prompts = f.read().splitlines()\n",
    "        self.templates = [p.strip() for p in raw_prompts]\n",
    "            \n",
    "        self.historyList = []\n",
    "        self.itemList = []\n",
    "        self.trueSelection = \"\"\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        prompt = self.templates[random.randint(0, len(self.templates)-1)]\n",
    "        history = \", \".join(self.historyList)\n",
    "        cans = \", \".join(self.itemList)\n",
    "        prompt = prompt.replace(\"[HistoryHere]\", history)\n",
    "        prompt = prompt.replace(\"[CansHere]\", cans)\n",
    "        prompt += \" \"\n",
    "        return prompt  \n",
    "def convert_dict_to_prompt(d:dict):\n",
    "        prompt_path=\"S-DPO/prompt/movie.txt\"  \n",
    "        t = Prompt(prompt_path)\n",
    "        d[\"historyList\"] = d[\"historyList\"].split(\"::\") if isinstance(d[\"historyList\"], str) else d[\"historyList\"]\n",
    "        t.historyList = d[\"historyList\"]\n",
    "        t.itemList = d[\"itemList\"]\n",
    "        t.trueSelection = d[\"trueSelection\"]\n",
    "        return t\n",
    "\n",
    "def process_data(data_point):\n",
    "    t = convert_dict_to_prompt(data_point)\n",
    "    prompt = str(t)\n",
    "    target = data_point[\"trueSelection\"]\n",
    "    dic = {\n",
    "        \"prompt\": prompt,\n",
    "        \"completion\": target\n",
    "    }\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = {\n",
    "    \"train\": \"./data/lastfm-sft-cans20/lastfm-train.json\",\n",
    "    \"validation\": \"./data/lastfm-sft-cans20/lastfm-val.json\",\n",
    "}\n",
    "\n",
    "data = load_dataset(\"json\", data_files=data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'itemList': ['Dolphin',\n",
       "  'HEARTSREVOLUTION',\n",
       "  'Simple Plan',\n",
       "  'M. Pokora',\n",
       "  'Shout Out Louds',\n",
       "  'Orient Expressions',\n",
       "  'Peter Bjorn and John',\n",
       "  'Mägo de Oz',\n",
       "  'The Boo Radleys',\n",
       "  'Baroness',\n",
       "  '7Seconds',\n",
       "  \"Israel Kamakawiwo'ole\",\n",
       "  'Fleetwood Mac',\n",
       "  'Julie London',\n",
       "  'Big Mama Thornton',\n",
       "  'David Lee Roth',\n",
       "  'Burning Spear',\n",
       "  'Dolly Parton',\n",
       "  'Terri Clark',\n",
       "  'Get Cape. Wear Cape. Fly'],\n",
       " 'historyList': 'Morcheeba::Enigma::Café Del Mar',\n",
       " 'trueSelection': 'Fleetwood Mac'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ec36cec89e34ffa803cf3e8e338be7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/47872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['prompt', 'completion'],\n",
      "    num_rows: 47872\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "train_data = data[\"train\"].shuffle(seed=42).map(process_data)\n",
    "train_data = train_data.remove_columns(data[\"train\"].column_names)\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': 'After watching Katy Perry, P!nk, Allison Iraheta, The Pussycat Dolls, Backstreet Boys, Savage Garden, Simple Plan, Adam Lambert, Jewel, John Williams, the person is presented with the following movie options We Are The Ocean, Bill Evans, The Tragically Hip, KC and the Sunshine Band, Alan Silvestri, The Alarm, Lacuna Coil, Azam Ali, Autograph, Slagsmålsklubben, Nelly, Bif Naked, Психея, Samantha Fox, Hooverphonic, The Fall, Beseech, The Ditty Bops, Mariana Aydar, Air. Can you predict her/his next choice?  Answer: ', 'completion': 'Alan Silvestri'}\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "S-DPO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
